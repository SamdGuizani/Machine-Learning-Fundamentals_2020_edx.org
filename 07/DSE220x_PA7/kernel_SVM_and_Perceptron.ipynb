{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments with kernel machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will use simple two-dimensional data sets to illustrate the behavior of the support vector machine and the Perceptron, when used with quadratic and RBF kernels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic training procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "matplotlib.rc('xtick', labelsize=14) \n",
    "matplotlib.rc('ytick', labelsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory containing this notebook should also contain two-dimensional data files, `data1.txt` through `data5.txt`. These files contain one data point per line, along with a label (either -1 or 1), like:\n",
    "* `3 8 -1` (meaning that point `x=(3,8)` has label `y=-1`)\n",
    "\n",
    "The next procedure, **learn_and_display_SVM**, loads one of these data sets, invokes `sklearn.SVC` to learn a classifier, and then displays the data as well as the boundary. It is invoked as follows:\n",
    "* `learn_and_display_SVM(datafile, kernel_type, C_value, s_value)`\n",
    "\n",
    "where\n",
    "* `datafile` is one of `'data1.txt'` through `'data5.txt'` (or another file in the same format)\n",
    "* `kernel_type` is either `'quadratic'` or `'rbf'`\n",
    "* `C_value` is the setting of the soft-margin parameter `C` (default: 1.0)\n",
    "* `s_value` (for the RBF kernel) is the scaling parameter `s` (default: 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_and_display_SVM(datafile, kernel_type='rbf', C_value=1.0, s_value=1.0):\n",
    "    data = np.loadtxt(datafile)\n",
    "    n,d = data.shape\n",
    "    # Create training set x and labels y\n",
    "    x = data[:,0:2]\n",
    "    y = data[:,2]\n",
    "    # Now train a support vector machine and identify the support vectors\n",
    "    if kernel_type == 'rbf':\n",
    "        clf = SVC(kernel='rbf', C=C_value, gamma=1.0/(s_value*s_value))\n",
    "    if kernel_type == 'quadratic':\n",
    "        clf = SVC(kernel='poly', degree=2, C=C_value, coef0=1.0)\n",
    "    clf.fit(x,y)\n",
    "    sv = np.zeros(n,dtype=bool)\n",
    "    sv[clf.support_] = True\n",
    "    notsv = np.logical_not(sv)\n",
    "    # Determine the x1- and x2- limits of the plot\n",
    "    x1min = min(x[:,0]) - 1\n",
    "    x1max = max(x[:,0]) + 1\n",
    "    x2min = min(x[:,1]) - 1\n",
    "    x2max = max(x[:,1]) + 1\n",
    "    plt.xlim(x1min,x1max)\n",
    "    plt.ylim(x2min,x2max)\n",
    "    # Plot the data points, enlarging those that are support vectors\n",
    "    plt.plot(x[(y==1)*notsv,0], x[(y==1)*notsv,1], 'ro')\n",
    "    plt.plot(x[(y==1)*sv,0], x[(y==1)*sv,1], 'ro', markersize=10)\n",
    "    plt.plot(x[(y==-1)*notsv,0], x[(y==-1)*notsv,1], 'k^')\n",
    "    plt.plot(x[(y==-1)*sv,0], x[(y==-1)*sv,1], 'k^', markersize=10)\n",
    "    # Construct a grid of points and evaluate classifier at each grid points\n",
    "    grid_spacing = 0.025\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, grid_spacing), np.arange(x2min, x2max, grid_spacing))\n",
    "    grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    Z = clf.decision_function(grid)\n",
    "    # Quantize the values to -1, -0.5, 0, 0.5, 1 for display purposes\n",
    "    for i in range(len(Z)):\n",
    "        Z[i] = min(Z[i],1.0)\n",
    "        Z[i] = max(Z[i],-1.0)\n",
    "        if (Z[i] > 0.0) and (Z[i] < 1.0):\n",
    "            Z[i] = 0.5\n",
    "        if (Z[i] < 0.0) and (Z[i] > -1.0):\n",
    "            Z[i] = -0.5\n",
    "    # Show boundary and margin using a color plot\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.pcolormesh(xx1, xx2, Z, cmap=plt.cm.PRGn, vmin=-2, vmax=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiments with the quadratic kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try out SVM on some examples, starting with the quadratic kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 1\n",
    "kernel_type = 'quadratic'\n",
    "\n",
    "for file in ['data1.txt', 'data2.txt', 'data3.txt', 'data4.txt', 'data5.txt']:\n",
    "    learn_and_display_SVM(file, kernel_type, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also try `data2.txt` through `data5.txt`. Also try changing the value of `C` (the third parameter) to see how that affects the boundary and margin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Experiments with the RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now experiment with the RBF kernel, on the same five data sets. This time there are two parameters to play with: `C` and `sigma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10.0\n",
    "s_value = 10\n",
    "kernel_type = 'rbf'\n",
    "\n",
    "for file in ['data1.txt', 'data2.txt', 'data3.txt', 'data4.txt', 'data5.txt']:\n",
    "    learn_and_display_SVM(file, kernel_type, C, s_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The kernel Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do:**</font> Implement the kernel Perceptron algorithm as specified in lecture. Your algorithm should allow both the quadratic and RBF kernel, and should follow roughly the same signature as the SVM routine above:\n",
    "* `learn_and_display_Perceptron(datafile, kernel_type, s_value)`\n",
    "\n",
    "Recall that the Perceptron algorithm does not always converge; you will need to explicitly check for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "### Any auxiliary functions that you need\n",
    "###\n",
    "\n",
    "def quadratic_kernel(x1, x2):\n",
    "    '''Returns quadratic kernel value for 2 vectors x1 and x2\n",
    "    Inputs:\n",
    "        x1, x2 = 2 vecors dimension d\n",
    "    Outpus:\n",
    "        k = kernel value'''\n",
    "    k = (1 + x1 @ x2)**2\n",
    "    return k\n",
    "\n",
    "\n",
    "def rbf_kernel(x1, x2, s_value):\n",
    "    '''Returns Radial Basis Function kernel value for 2 vectors x1 and x2\n",
    "    Inputs:\n",
    "        x1, x2 = 2 vecors dimension d\n",
    "    Outpus:\n",
    "        k = kernel value'''\n",
    "    k = np.exp(-np.linalg.norm(x1 - x2) / s_value**2)\n",
    "    return k\n",
    "\n",
    "\n",
    "def quadratic_kernel_matrix(x):\n",
    "    '''Returns quadratic kernel matrix K of a dataset x.\n",
    "    Inputs:\n",
    "        x = dataset matrix of size (n x d). n datapoints, d features.\n",
    "    Outputs:\n",
    "        K = kernel matrix. K[i,j] = (1 + x[i] @ x[j])**2'''\n",
    "    n, d = x.shape\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i,j] = quadratic_kernel(x[i], x[j])\n",
    "    return K\n",
    "\n",
    "\n",
    "def rbf_kernel_matrix(x, s_value):\n",
    "    '''Returns Radial Basis Function (RBF) kernel matrix K of a dataset x.\n",
    "    Inputs:\n",
    "        x = dataset matrix of size (n x d). n datapoints, d features.\n",
    "    Outputs:\n",
    "        K = kernel matrix. K[i,j] = np.exp(-np.linalg.norm(x[i] - x[j]) / s_value**2)'''\n",
    "    n, d = x.shape\n",
    "    K = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            K[i,j] = rbf_kernel(x[i], x[j], s_value)\n",
    "    return K\n",
    "\n",
    "\n",
    "def learn_and_display_Perceptron(datafile, kernel_type='rbf', s_value=1.0):\n",
    "    ###\n",
    "    ### Your code\n",
    "    ###\n",
    "    data = np.loadtxt(datafile)\n",
    "    n,d = data.shape\n",
    "    \n",
    "    # Create training set x and labels y\n",
    "    x = data[:,0:2]\n",
    "    y = data[:,2]\n",
    "    \n",
    "    # Choose kernel\n",
    "    if kernel_type == 'quadratic':\n",
    "        K = quadratic_kernel_matrix(x)\n",
    "    if kernel_type == 'rbf':\n",
    "        K = rbf_kernel_matrix(x,s_value)\n",
    "    \n",
    "    # Perceptron\n",
    "    N_iter = 1000 # number of passes through dataset\n",
    "    alpha = np.zeros(n)\n",
    "    b = 0\n",
    "    alphas = np.zeros((n, N_iter))\n",
    "    bs = []\n",
    "    \n",
    "    for t in range(N_iter):\n",
    "        for i in range(n):\n",
    "            if y[i] * (np.sum(alpha * y * K[i,:] + b)) <= 0:\n",
    "                alpha[i] = alpha[i] + 1\n",
    "                b = b + y[i]\n",
    "        alphas[:, t] = alpha\n",
    "        bs.append(b)\n",
    "    \n",
    "    # Identify points used by classifier\n",
    "    sv = np.zeros(n,dtype=bool)\n",
    "    sv[alpha > 0] = True\n",
    "    notsv = np.logical_not(sv)\n",
    "    \n",
    "    # Determine the x1- and x2- limits of the plot\n",
    "    x1min = min(x[:,0]) - 1\n",
    "    x1max = max(x[:,0]) + 1\n",
    "    x2min = min(x[:,1]) - 1\n",
    "    x2max = max(x[:,1]) + 1\n",
    "    plt.xlim(x1min,x1max)\n",
    "    plt.ylim(x2min,x2max)\n",
    "    \n",
    "    # Plot the data points, enlarging those that are support vectors\n",
    "    plt.plot(x[(y==1)*notsv,0], x[(y==1)*notsv,1], 'ro')\n",
    "    plt.plot(x[(y==1)*sv,0], x[(y==1)*sv,1], 'ro', markersize=10)\n",
    "    plt.plot(x[(y==-1)*notsv,0], x[(y==-1)*notsv,1], 'k^')\n",
    "    plt.plot(x[(y==-1)*sv,0], x[(y==-1)*sv,1], 'k^', markersize=10)\n",
    "    \n",
    "    # Construct a grid of points and evaluate classifier at each grid points\n",
    "    grid_spacing = 0.05\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1min, x1max, grid_spacing), np.arange(x2min, x2max, grid_spacing))\n",
    "    grid = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    \n",
    "    # Predict label of each point in grid\n",
    "    Z = np.zeros(grid.shape[0])\n",
    "    \n",
    "    if kernel_type == 'quadratic':\n",
    "        K_ = np.zeros(n)\n",
    "        for j in range(grid.shape[0]):\n",
    "            for i in range(n):\n",
    "                K_[i] = quadratic_kernel(grid[j], x[i])\n",
    "            Z[j] = np.sign(np.sum(alpha * y * K_ + b))\n",
    "            \n",
    "    if kernel_type == 'rbf':\n",
    "        K_ = np.zeros(n)\n",
    "        for j in range(grid.shape[0]):\n",
    "            for i in range(n):\n",
    "                K_[i] = rbf_kernel(grid[j], x[i], s_value)\n",
    "            Z[j] = np.sign(np.sum(alpha * y * K_ + b))\n",
    "    \n",
    "    # Show boundary and margin using a color plot\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.pcolormesh(xx1, xx2, Z, cmap=plt.cm.PRGn, vmin=-2, vmax=2)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return alpha, b, np.asmatrix(alphas), bs, Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Kernel Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "kernel_type = 'quadratic'\n",
    "\n",
    "for file in ['data1.txt', 'data2.txt', 'data3.txt', 'data4.txt', 'data5.txt']:\n",
    "    alpha, b, alphas, bs, Z = learn_and_display_Perceptron(file, \n",
    "                                                       kernel_type=kernel_type, \n",
    "                                                       s_value=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBF Kernel Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_type = 'rbf'\n",
    "\n",
    "for file in ['data1.txt', 'data2.txt', 'data3.txt', 'data4.txt', 'data5.txt']:\n",
    "    alpha, b, alphas, bs, Z = learn_and_display_Perceptron(file, \n",
    "                                                       kernel_type=kernel_type, \n",
    "                                                       s_value=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Experiment with your routine, on the same five data sets.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "117px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
