{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winery classification with the multivariate Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we return to winery classification, using the full set of 13 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load in the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by loading in the Wine data set. Make sure the file `wine.data.txt` is in the same directory as this notebook.\n",
    "\n",
    "Recall that there are 178 data points, each with 13 features and a label (1,2,3). As before, we will divide this into a training set of 130 points and a test set of 48 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard includes\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Useful module for dealing with the Gaussian density\n",
    "from scipy.stats import norm, multivariate_normal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data set.\n",
    "data = np.loadtxt('wine.data.txt', delimiter=',')\n",
    "# Names of features\n",
    "featurenames = ['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash','Magnesium', 'Total phenols', \n",
    "                'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins', 'Color intensity', 'Hue', \n",
    "                'OD280/OD315 of diluted wines', 'Proline']\n",
    "# Split 178 instances into training set (trainx, trainy) of size 130 and test set (testx, testy) of size 48\n",
    "np.random.seed(0)\n",
    "perm = np.random.permutation(178)\n",
    "trainx = data[perm[0:130],1:14]\n",
    "trainy = data[perm[0:130],0]\n",
    "testx = data[perm[130:178], 1:14]\n",
    "testy = data[perm[130:178],0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.388e+01, 1.890e+00, 2.590e+00, 1.500e+01, 1.010e+02, 3.250e+00,\n",
       "        3.560e+00, 1.700e-01, 1.700e+00, 5.430e+00, 8.800e-01, 3.560e+00,\n",
       "        1.095e+03],\n",
       "       [1.242e+01, 2.550e+00, 2.270e+00, 2.200e+01, 9.000e+01, 1.680e+00,\n",
       "        1.840e+00, 6.600e-01, 1.420e+00, 2.700e+00, 8.600e-01, 3.300e+00,\n",
       "        3.150e+02],\n",
       "       [1.281e+01, 2.310e+00, 2.400e+00, 2.400e+01, 9.800e+01, 1.150e+00,\n",
       "        1.090e+00, 2.700e-01, 8.300e-01, 5.700e+00, 6.600e-01, 1.360e+00,\n",
       "        5.600e+02],\n",
       "       [1.258e+01, 1.290e+00, 2.100e+00, 2.000e+01, 1.030e+02, 1.480e+00,\n",
       "        5.800e-01, 5.300e-01, 1.400e+00, 7.600e+00, 5.800e-01, 1.550e+00,\n",
       "        6.400e+02],\n",
       "       [1.383e+01, 1.570e+00, 2.620e+00, 2.000e+01, 1.150e+02, 2.950e+00,\n",
       "        3.400e+00, 4.000e-01, 1.720e+00, 6.600e+00, 1.130e+00, 2.570e+00,\n",
       "        1.130e+03]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testx[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 3., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define a function that fits a Gaussian generative model to the data.\n",
    "For each class (`j=1,2,3`), we have:\n",
    "* `pi[j]`: the class weight\n",
    "* `mu[j,:]`: the mean, a 13-dimensional vector\n",
    "* `sigma[j,:,:]`: the 13x13 covariance matrix\n",
    "\n",
    "This means that `pi` is a 4x1 array (Python arrays are indexed starting at zero, and we aren't using `j=0`), `mu` is a 4x13 array and `sigma` is a 4x13x13 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 3  # labels 1,2,...,k\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k+1,d))\n",
    "    sigma = np.zeros((k+1,d,d))\n",
    "    pi = np.zeros(k+1)\n",
    "    for label in range(1,k+1):\n",
    "        indices = (y == label)\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=0, bias=1)\n",
    "        pi[label] = float(sum(indices))/float(len(y))\n",
    "    return mu, sigma, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a Gaussian generative model to the training data\n",
    "mu, sigma, pi = fit_generative_model(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.37853488e+01 2.02232558e+00 2.42790698e+00 1.68813953e+01\n",
      " 1.05837209e+02 2.85162791e+00 2.99627907e+00 2.89069767e-01\n",
      " 1.93069767e+00 5.63023256e+00 1.06232558e+00 3.16674419e+00\n",
      " 1.14190698e+03]\n",
      "[  2.42790698 105.8372093    2.99627907]\n"
     ]
    }
   ],
   "source": [
    "print(mu[1]) # Mean for label 1\n",
    "print(mu[1,[2, 4, 6]]) # Mean for label 1 on features [2,4,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.23325279 0.         0.        ]\n",
      " [0.         0.03677469 0.        ]\n",
      " [0.         0.         0.15240941]]\n",
      "(13, 13)\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "# print(sigma[i]) # Cov matrix of class i\n",
    "# print(sigma[i][[2,4,6],:][:,[2,4,6]]) # slicing 3-D array for features 2, 4 and 6\n",
    "print(np.diag(sigma[[i],[0,2,6],[0,2,6]])) # slicing 3-D array for features 0, 2 and 6 AND assuming independence \n",
    "print(sigma[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.33076923, 0.41538462, 0.25384615])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use the model to make predictions on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**For you to do**</font>: Define a general purpose testing routine that takes as input:\n",
    "* the arrays `pi`, `mu`, `sigma` defining the generative model, as above\n",
    "* the test set (points `tx` and labels `ty`)\n",
    "* a list of features `features` (chosen from 0-12)\n",
    "\n",
    "It should return the number of mistakes made by the generative model on the test data, *when restricted to the specified features*. For instance, using the just three features 2 (`'Ash'`), 4 (`'Magnesium'`) and 6 (`'Flavanoids'`) results in 7 mistakes (out of 48 test points), so \n",
    "\n",
    "        `test_model(mu, sigma, pi, [2,4,6], testx, testy)` \n",
    "\n",
    "should print 7/48.\n",
    "\n",
    "**Hint:** The way you restrict attention to a subset of features is by choosing the corresponding coordinates of the full 13-dimensional mean and the appropriate submatrix of the full 13x13 covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now test the performance of a predictor based on a subset of features\n",
    "def test_model(mu, sigma, pi, features, tx, ty):\n",
    "    ###\n",
    "    ### Your code goes here   \n",
    "    ###\n",
    "    \n",
    "    nb_labels = pi.shape[0]-1\n",
    "    n, d = tx.shape\n",
    "    \n",
    "    # classify data points in tx\n",
    "    t_prd = np.zeros((n, nb_labels+1)) # predicted labels in 1st column, scores for each lable in 2nd to last columns\n",
    "    for i in range(n):\n",
    "        for label in range (1, nb_labels+1):\n",
    "            t_prd[i, label] = np.log(pi[label]) + multivariate_normal.logpdf(tx[i][features], \n",
    "                                                                             mean=mu[label][features], \n",
    "                                                                             cov=sigma[label][features,:][:,features])\n",
    "        t_prd[i,0] = np.argmax(t_prd[i,1:]) + 1\n",
    "    \n",
    "    # count miscalassified points\n",
    "    misclassified = (t_prd[:,0] != ty)\n",
    "    n_misclassified = np.sum(misclassified)\n",
    "    \n",
    "    return n_misclassified\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [2, 4, 6]\n",
    "n_misclassified = test_model(mu, sigma, pi, features, tx=testx, ty=testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"magenta\">Fast exercises</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note down the answers to these questions. You will need to enter them as part of this week's assignment.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 1. How many errors are made on the test set when using the single feature 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2. How many errors when using 'Alcohol' and 'Ash'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [0,2], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3. How many errors when using 'Alcohol', 'Ash', and 'Flavanoids'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, [0,2,6], testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 4. How many errors when using all 13 features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(mu, sigma, pi, range(0,13), testx, testy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 5. In lecture, we got somewhat different answers to these questions. Why do you think that might be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
