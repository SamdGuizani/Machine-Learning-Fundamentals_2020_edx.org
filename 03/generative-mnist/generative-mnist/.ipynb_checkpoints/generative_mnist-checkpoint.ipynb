{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian generative models for handwritten digit classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the 1-NN classifier yielded a 3.09% test error rate on the MNIST data set of handwritten digits. We will now see that a Gaussian generative model does almost as well, while being significantly faster and more compact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up notebook and load in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, we start by importing the required packages and data. For this notebook we will be using the *entire* `MNIST` dataset. The code below defines some helper functions that will load `MNIST` onto your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import gzip, os\n",
    "import numpy as np\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    from urllib import urlretrieve\n",
    "else:\n",
    "    from urllib.request import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that downloads a specified MNIST data file from Yann Le Cun's website\n",
    "def download(filename, source='http://yann.lecun.com/exdb/mnist/'):\n",
    "    print(\"Downloading %s\" % filename)\n",
    "    urlretrieve(source + filename, filename)\n",
    "\n",
    "# Invokes download() if necessary, then reads in images\n",
    "def load_mnist_images(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=16)\n",
    "    data = data.reshape(-1,784)\n",
    "    return data\n",
    "\n",
    "def load_mnist_labels(filename):\n",
    "    if not os.path.exists(filename):\n",
    "        download(filename)\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        data = np.frombuffer(f.read(), np.uint8, offset=8)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load in the training set and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train-images-idx3-ubyte.gz\n",
      "Downloading train-labels-idx1-ubyte.gz\n",
      "Downloading t10k-images-idx3-ubyte.gz\n",
      "Downloading t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "## Load the training set\n",
    "train_data = load_mnist_images('train-images-idx3-ubyte.gz')\n",
    "train_labels = load_mnist_labels('train-labels-idx1-ubyte.gz')\n",
    "\n",
    "## Load the testing set\n",
    "test_data = load_mnist_images('t10k-images-idx3-ubyte.gz')\n",
    "test_labels = load_mnist_labels('t10k-labels-idx1-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function **displaychar** shows a single MNIST digit. To do this, it first has to reshape the 784-dimensional vector into a 28x28 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def displaychar(image):\n",
    "    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAFKUlEQVR4nO3dsU9TawDG4XtujI2BARJjF+LKzlwIU900xkT/AFgcmFhYWEggxM2VhdGElYVBYySOXUxM/AOcjA7EmDBAPHe60/V8V0s5fVueZ33Tnm/55RtOKFVd1/VfQJy/x30A4NfECaHECaHECaHECaFulcaqqto6B9xYTS9M3JwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQ6ta4D0CW7e3txm1nZ6f42Y8fPxb3vb294v7q1aviftO4OSGUOCGUOCGUOCGUOCGUOCGUOCFUVdd13ThWVZtnibG7u1vcj46OivuHDx9GeZyR6nQ6xf3bt2+N28zMzJWefXp6WtxXV1ev9P2TqilBNyeEEieEEieEEieEEieEEieEmto/GZufn2/cHj58WPzs8+fPi/v6+npxX1hYKO4XFxfFfZyu+rqE0XFzQihxQihxQihxQihxQihxQihxQqipfc+5uLjYuB0eHl7rs2/qn9oxWm5OCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCCVOCDW1v1s7Tg8ePCjux8fHLZ2ESebmhFDihFDihFDihFDihFDihFBT+yql1+uN7dmbm5vF/e3bt43bjx8/ip99/Phxcb9//35xf/ToUXEnh5sTQokTQokTQokTQokTQokTQokTQlV1XdeNY1W1eZaRevfuXeO2vLzc4kn+68uXL43b5eVl8bN3794t7p1OZ6gztaHf7xf3169ft3SSLE0JujkhlDghlDghlDghlDghlDghlDgh1MT+PefKykpxX1paaukkf67b7Y77CGPx/fv3cR9horg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdTEvuf89OlTcX///n3j9n//oo/hnJ2dFfe5ubmWTjId3JwQSpwQSpwQSpwQSpwQSpwQSpwQamp/t7b0+67Pnj0rfnZra2vUxxmZg4OD4v7169fi/uLFi+I+Ozv7x2f61+fPn4v7YDAo7k+ePBn62ZPM79bChBEnhBInhBInhBInhBInhJraVyn82suXL4v7xsbGtT379PS0uK+url7bs5N5lQITRpwQSpwQSpwQSpwQSpwQSpwQamJ/GpPhvHnzprhf53tO/oybE0KJE0KJE0KJE0KJE0KJE0KJE0J5z3nD9Hq9cR+B3+TmhFDihFDihFDihFDihFDihFDihFDec94wnU5n3EfgN7k5IZQ4IZQ4IZQ4IZQ4IZQ4IZRXKVPm3r17xf3p06ctnYSrcnNCKHFCKHFCKHFCKHFCKHFCKHFCKO85p8zt27eLe7fbbekkXJWbE0KJE0KJE0KJE0KJE0KJE0KJE0J5zzllfv78WdzPz8+L+507d4Z+9mAwKO77+/tDf/dN5OaEUOKEUOKEUOKEUOKEUOKEUOKEUFVd13XjWFVtnoUW9Pv94n5ycjL0d6+trRX3w8PDob97mjUl6OaEUOKEUOKEUOKEUOKEUOKEUOKEUN5zwph5zwkTRpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQ6lZpLPxqJnDN3JwQSpwQSpwQSpwQSpwQSpwQ6h+QUqQ9AnZB9gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displaychar(train_data[58])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training set consists of 60,000 images. Thus `train_data` should be a 60000x784 array while `train_labels` should be 60000x1. Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape, train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fit a Gaussian generative model to the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=\"magenta\">For you to do:</font>** Define a function, **fit_generative_model**, that takes as input a training set (data `x` and labels `y`) and fits a Gaussian generative model to it. It should return the parameters of this generative model; for each label `j = 0,1,...,9`, we have:\n",
    "* `pi[j]`: the frequency of that label\n",
    "* `mu[j]`: the 784-dimensional mean vector\n",
    "* `sigma[j]`: the 784x784 covariance matrix\n",
    "\n",
    "This means that `pi` is 10x1, `mu` is 10x784, and `sigma` is 10x784x784.\n",
    "\n",
    "We have already seen how to fit a Gaussian generative model in the Winery example, but now there is an added ingredient. <font color=\"magenta\">The empirical covariances are very likely to be singular (or close to singular), which means that we won't be able to do calculations with them</font>. Thus it is important to **regularize** these matrices. The standard way of doing this is to add `cI` to them, where `c` is some constant and `I` is the 784-dimensional identity matrix. (To put it another way, we compute the empirical covariances and then increase their diagonal entries by some constant `c`.)\n",
    "\n",
    "This modification is guaranteed to yield covariance matrices that are non-singular, for any `c > 0`, no matter how small. But this doesn't mean that we should make `c` as small as possible. Indeed, `c` is now a parameter, and by setting it appropriately, we can improve the performance of the model. We will study **regularization** in greater detail over the coming weeks.\n",
    "\n",
    "Your routine needs to choose a good setting of `c`. Crucially, this needs to be done using the training set alone. So you might try setting aside part of the training set as a validation set, or using some kind of cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_generative_model(x,y):\n",
    "    k = 10  # labels 0,1,...,k-1\n",
    "    d = (x.shape)[1]  # number of features\n",
    "    mu = np.zeros((k,d))\n",
    "    sigma = np.zeros((k,d,d))\n",
    "    pi = np.zeros(k)\n",
    "    ###\n",
    "    ### Your code goes here        \n",
    "    ###\n",
    "    for label in range(k):\n",
    "        indices = (y == label)\n",
    "        pi[label] = np.sum(indices) / len(y)\n",
    "        mu[label] = np.mean(x[indices,:], axis=0)\n",
    "        sigma[label] = np.cov(x[indices,:], rowvar=False, bias=True)\n",
    "        \n",
    "    # Halt and return parameters\n",
    "    return mu, sigma, pi\n",
    "\n",
    "def sigma_regularization(sigma, c):\n",
    "    '''Returns a regularized covariance matrix.\n",
    "    Inputs:\n",
    "        - sigma = square matrix (dxd) that can be singular\n",
    "        - c = regularization constant (c > 0)\n",
    "    Outputs:\n",
    "        - sigma_reg = square matrix (dxd) = sigma + c * Identity(d)'''\n",
    "    \n",
    "    d = sigma.shape[1]\n",
    "    sigma_reg = sigma + c * np.eye(d)\n",
    "    \n",
    "    return sigma_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's try out your function. In particular, we will use **displaychar** to visualize the means of the Gaussians for the first three digits. You can try the other digits on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma, pi = fit_generative_model(train_data, train_labels)\n",
    "displaychar(mu[0])\n",
    "displaychar(mu[1])\n",
    "displaychar(mu[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_reg = sigma_regularization(sigma, c=1)\n",
    "\n",
    "try:\n",
    "    np.linalg.inv(sigma_reg[1])\n",
    "except:\n",
    "    print('Singular matrix') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make predictions on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how many errors your model makes on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance matrix regularization constant =  3000\n",
      "Your model makes 435 errors out of 10000\n",
      "This is 4.35% error rate\n",
      "\n",
      "\n",
      "Covariance matrix regularization constant =  3500\n",
      "Your model makes 438 errors out of 10000\n",
      "This is 4.38% error rate\n",
      "\n",
      "\n",
      "Covariance matrix regularization constant =  4000\n",
      "Your model makes 431 errors out of 10000\n",
      "This is 4.31% error rate\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute log Pr(label|image) for each [test image,label] pair.\n",
    "k = 10\n",
    "score = np.zeros((len(test_labels),k))\n",
    "\n",
    "for c in [3000, 3500, 4000]:\n",
    "    for label in range(0,k):\n",
    "        rv = multivariate_normal(mean=mu[label], cov=sigma_regularization(sigma, c)[label])\n",
    "        for i in range(0,len(test_labels)):\n",
    "           score[i,label] = np.log(pi[label]) + rv.logpdf(test_data[i,:])\n",
    "    predictions = np.argmax(score, axis=1)\n",
    "    # Finally, tally up score\n",
    "    errors = np.sum(predictions != test_labels)\n",
    "    print(\"Covariance matrix regularization constant = \", c)\n",
    "    print(\"Your model makes \" + str(errors) + \" errors out of 10000\")\n",
    "    print(\"This is \" + str(errors/100) + \"% error rate\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Quick exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*You will need to answer variants of these questions as part of this week's assignment*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 1:</font> What happens if you do not regularize the covariance matrices?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 2:</font> What happens if you set the value of `c` too high, for instance to one billion? Do you understand why this happens?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">Exercise 3:</font> What value of c did you end up using? How many errors did your model make on the training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">If you have the time</font>: We have talked about using the same regularization constant `c` for all ten classes. What about using a different value of `c` for each class? How would you go about choosing these? Can you get better performance in this way?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
